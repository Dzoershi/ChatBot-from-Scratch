{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a499c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16dba8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "if TOGETHER_API_KEY is None:\n",
    "    raise ValueError(\"‚ùå API key not loaded. Check your .env file name or path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07fdbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticChatbot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        intents_path,\n",
    "        model_name='all-MiniLM-L6-v2',\n",
    "        embeddings_path=\"embeddings.pt\",\n",
    "        together_model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    ):\n",
    "        self.intents_path = intents_path\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.together_model_name = together_model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.patterns = []\n",
    "        self.responses = []\n",
    "        self.embeddings = None\n",
    "\n",
    "        self._load_data()\n",
    "        self._load_or_build_embeddings()\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(self.intents_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.patterns = [item[\"pattern\"] for item in data[\"intents\"]]\n",
    "        self.responses = [item[\"responses\"] for item in data[\"intents\"]]\n",
    "\n",
    "    def _load_or_build_embeddings(self):\n",
    "        if os.path.exists(self.embeddings_path):\n",
    "            print(f\"üì• Chargement des embeddings depuis {self.embeddings_path}...\")\n",
    "            self.embeddings = torch.load(self.embeddings_path)\n",
    "        else:\n",
    "            print(\"üîÑ Encodage des patterns avec SBERT...\")\n",
    "            self.embeddings = self.model.encode(self.patterns, convert_to_tensor=True)\n",
    "            torch.save(self.embeddings, self.embeddings_path)\n",
    "            print(f\"üíæ Embeddings sauvegard√©s dans {self.embeddings_path}\")\n",
    "\n",
    "    def build_prompt(self, user_input, top_k_hits):\n",
    "        examples = \"\"\n",
    "        for i, hit in enumerate(top_k_hits[:3]):\n",
    "            idx = hit[\"corpus_id\"]\n",
    "            question = self.patterns[idx]\n",
    "            answer = random.choice(self.responses[idx])\n",
    "            examples += f\"User: {question}\\nBot: {answer}\\n\\n\"\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant. Below are a few example conversations.\\n\"\n",
    "            \"Use them to respond to the final user input in a concise and natural way.\\n\\n\"\n",
    "            f\"{examples}\"\n",
    "            f\"User: {user_input}\\nBot:\"\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def generate_with_together(self, prompt, max_tokens=150):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"model\": self.together_model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"stop\": [\"User:\", \"Bot:\"]\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.together.xyz/v1/completions\", headers=headers, json=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(\"‚ùå Error from Together API:\", response.text)\n",
    "            return \"D√©sol√©, j'ai eu un probl√®me pour r√©pondre.\"\n",
    "\n",
    "        return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    def get_response(self, user_input, top_k=5):\n",
    "        query_embedding = self.model.encode(user_input, convert_to_tensor=True)\n",
    "        hits = util.semantic_search(query_embedding, self.embeddings, top_k=top_k)[0]\n",
    "\n",
    "        if not hits:\n",
    "            return \"Je ne suis pas s√ªr de comprendre.\"\n",
    "\n",
    "        prompt = self.build_prompt(user_input, hits)\n",
    "        return self.generate_with_together(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aff6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Chargement du chatbot s√©mantique avec Together.ai...\n",
      "üì• Chargement des embeddings depuis embeddings.pt...\n",
      "\n",
      "ü§ñ Chatbot pr√™t ! Tape une phrase (ou /quit pour quitter)\n",
      "\n",
      "ü§ñ Bot: Ireland is a country located in Europe. It is not part of Britain or America.\n",
      "ü§ñ Bot: Neither actually . New Zealand is an independent nation with its own government and monarch .\n",
      "üëã Bye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"üöÄ Chargement du chatbot s√©mantique avec Together.ai...\")\n",
    "    bot = SemanticChatbot(\"dailydialog_sbert.json\")\n",
    "\n",
    "    print(\"\\nü§ñ Chatbot pr√™t ! Tape une phrase (ou /quit pour quitter)\\n\")\n",
    "    while True:\n",
    "        message = input(\"üó£Ô∏è You: \")\n",
    "        if message.strip().lower() == \"/quit\":\n",
    "            print(\"üëã Bye!\")\n",
    "            break\n",
    "\n",
    "        response = bot.get_response(message)\n",
    "        print(f\"ü§ñ Bot: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
